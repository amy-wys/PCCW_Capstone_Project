{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRYSu48huSUW",
        "outputId": "64e4984b-4b62-4709-847a-a021d4730a8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m759.0/759.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.4/46.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m922.4/922.4 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m364.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.9/66.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m88.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m414.1/414.1 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for hnswlib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip -q install langchain openai tiktoken chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-KFB7J_u_3L",
        "outputId": "a29ed872-d0bc-41ef-bb72-b6a0fe426a08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: langchain\n",
            "Version: 0.0.161\n",
            "Summary: Building applications with LLMs through composability\n",
            "Home-page: https://www.github.com/hwchase17/langchain\n",
            "Author: \n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: aiohttp, async-timeout, dataclasses-json, numexpr, numpy, openapi-schema-pydantic, pydantic, PyYAML, requests, SQLAlchemy, tenacity, tqdm\n",
            "Required-by: \n"
          ]
        }
      ],
      "source": [
        "!pip show langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6XPLPVrqEaV"
      },
      "outputs": [],
      "source": [
        "!wget -q https://www.dropbox.com/s/vs6ocyvpzzncvwh/new_articles.zip\n",
        "!unzip -q new_articles.zip -d new_articles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AnZQpL_IZZZ"
      },
      "source": [
        "# LangChain multi-doc retriever with ChromaDB\n",
        "\n",
        "***New Points***\n",
        "- Multiple Files\n",
        "- ChromaDB\n",
        "- Source info\n",
        "- gpt-3.5-turbo API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqwsGJDhvAQ5"
      },
      "source": [
        "## Setting up LangChain\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dNA4TsHpu6OM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "OPEN_API_KEY = os.getenv(\"OPENAI_API_KEY\", None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XHVE9uFb3Ajj"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.document_loaders import DirectoryLoader\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UcQKUId3X2M"
      },
      "source": [
        "## Load multiple and process documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PRSeXXc_3Ypj"
      },
      "outputs": [],
      "source": [
        "# Load and process the text files\n",
        "# loader = TextLoader('single_text_file.txt')\n",
        "loader = DirectoryLoader('./data/', glob=\"./*.pdf\", loader_cls=PyPDFLoader)\n",
        "\n",
        "documents = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3__nT0D4Fkmg"
      },
      "outputs": [],
      "source": [
        "#splitting the text into\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "texts = text_splitter.split_documents(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlU5AlqY4gwj",
        "outputId": "d78fb098-3161-42cd-8ce9-5f98f4ef91d2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "91"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bg6-9jwU4ja_",
        "outputId": "02f45055-0e09-42ba-9ff3-0e7850f06cae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(page_content='both concurrently and  longitudinally6. This suggests that social anxiety may contribute to poorer outcomes in \\nindividuals with psychosis, even when present at subclinical levels.\\nParanoia, the exaggerated belief that intentional harm is done or will be done by  others7, is a common symp-\\ntom of psychosis. Paranoia can manifest in milder forms as ideas of social reference or more severe forms as \\npersecutory delusions 8. Albeit being distinct phenomena, paranoia and social anxiety are both characterized by \\nappraisals of social threat: paranoia concerns imminent and ongoing physical, psychological or social harms by \\n others7, whereas social anxiety reflects worry about rejection, embarrassment and  scrutiny9. Among individuals \\nwith first-episode psychosis, those with comorbid social anxiety disorder reported more persecutory threats than \\nthose without  comorbidity3. Across non-patient and community samples, correlations between subclinical levels', metadata={'source': 'data/s41598-023-47912-0.pdf', 'page': 0})"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "texts[3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsYsIy8F4cdm"
      },
      "source": [
        "## create the DB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_eTIZwf4Dk2",
        "outputId": "1cd293c4-716c-402d-d41b-045b6a264041"
      },
      "outputs": [],
      "source": [
        "# Embed and store the texts\n",
        "# Supplying a persist_directory will store the embeddings on disk\n",
        "persist_directory = 'db'\n",
        "\n",
        "## here we are using OpenAI embeddings but in future we will swap out to local embeddings\n",
        "embedding = OpenAIEmbeddings()\n",
        "\n",
        "vectordb = Chroma.from_documents(documents=texts,\n",
        "                                 embedding=embedding,\n",
        "                                 persist_directory=persist_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "uRfD_Te-47lb"
      },
      "outputs": [],
      "source": [
        "# persiste the db to disk\n",
        "vectordb.persist()\n",
        "vectordb = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-h1y_eAHmD-",
        "outputId": "4a6097fb-e30e-4fa2-ff4d-b972ce7f6154"
      },
      "outputs": [],
      "source": [
        "# Now we can load the persisted database from disk, and use it as normal.\n",
        "vectordb = Chroma(persist_directory=persist_directory,\n",
        "                  embedding_function=embedding)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siLXR-XT0JoI"
      },
      "source": [
        "## Make a retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6ObunFU30Lxh"
      },
      "outputs": [],
      "source": [
        "retriever = vectordb.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cYA-H59u0Skn"
      },
      "outputs": [],
      "source": [
        "docs = retriever.get_relevant_documents(\"What is paranoia?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0iAuh_B0ZjE",
        "outputId": "2ffd1da1-ff6c-4ea9-c361-7230dbd5bdc0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "jVWgPJXs1yRq"
      },
      "outputs": [],
      "source": [
        "retriever = vectordb.as_retriever(search_kwargs={\"k\": 2})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "H4N0IhRM0hHL",
        "outputId": "f8058122-1c8a-4c5b-f046-14a90eed5a3b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'similarity'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retriever.search_type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jXL9u-u0prF",
        "outputId": "2e6dd94e-bede-4e05-c841-9c755ecfef2a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'k': 2}"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retriever.search_kwargs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ia-4OXa5IeP"
      },
      "source": [
        "## Make a chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "MGx8XblM4shW"
      },
      "outputs": [],
      "source": [
        "# create the chain to answer questions\n",
        "qa_chain = RetrievalQA.from_chain_type(llm=OpenAI(),\n",
        "                                  chain_type=\"stuff\",\n",
        "                                  retriever=retriever,\n",
        "                                  return_source_documents=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "LZEo26mw8e5k"
      },
      "outputs": [],
      "source": [
        "## Cite sources\n",
        "def process_llm_response(llm_response):\n",
        "    print(llm_response['result'])\n",
        "    print('\\n\\nSources:')\n",
        "    for source in llm_response[\"source_documents\"]:\n",
        "        print(source.metadata['source'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKfX4vX-5RFT",
        "outputId": "b3902fd2-86cc-4020-86a9-99883a996d20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Paranoia is a mental disorder characterized by extreme suspiciousness and mistrust of others.\n",
            "\n",
            "\n",
            "Sources:\n",
            "data/s41598-023-47912-0.pdf\n",
            "data/s41598-023-47912-0.pdf\n"
          ]
        }
      ],
      "source": [
        "# full example\n",
        "query = \"What is paranoia?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olRm73t3rNt2",
        "outputId": "20fb1b17-6562-421d-a60e-c67b97ca67d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'query': 'How many young adults (or people) took part in this?',\n",
              " 'result': ' 134 participants took part in the study.',\n",
              " 'source_documents': [Document(page_content='replications in the clinical populations.\\nMethods\\nEthics approval for the study was granted by the Survey and Behavioral Research Ethics Committee of The Chi-\\nnese University of Hong Kong (Reference no.: SBRE-19–788). All methods were carried out in accordance with \\nrelevant guidelines and regulations. Informed consent was obtained from all participants.\\nParticipants\\nEligible participants aged 18–30 were recruited either from the subject pool of the Introductory Psychology \\ncourse or via campus recruitment. Participants with any past or current psychiatric diagnosis (self-reported \\nand then confirmed with a diagnostic clinical interview, see Measures) and who could not read Chinese were \\nexcluded. We targeted a sample size of 130, which is comparable to previous ESM studies with non-clinical \\nsamples analyzed using the dynamics structural equational modelling (DSEM) (see Statistical Analysis)55–57.', metadata={'page': 4, 'source': 'data/s41598-023-47912-0.pdf'}),\n",
              "  Document(page_content='Results\\nSample characteristics\\nOne hundred and fifty-four participants consented and took part in the study. Twenty participants were excluded \\ndue to a past or current psychiatric diagnosis (n = 18), or a subthreshold completion rate of the ESM assessment \\n(see ‘Methods’ section, n  = 2). Therefore, the final sample consisted of ESM data from 134 participants. The \\nmajority of our sample consisted of undergraduate students (n = 116, 86.6%), while the remaining (n = 18, 13.4%) \\nwere adults from the general population. A total of 5,800 ESM entries were entered into the Dynamic Structural \\nEquation Modelling (DSEM) analyses (mean completion rate: 72.1%, SD  = 0.16, range  = 36.7% – 100%). The \\nmean duration between two consecutive ESM entries within a day was 80.18\\xa0min (SD = 19.31, range  = 15–147). \\nThe descriptive statistics of participants’ demographic information and baseline survey can be found in Table\\xa0 1.\\nDynamic structural equation modelling (DSEM) analyses', metadata={'page': 1, 'source': 'data/s41598-023-47912-0.pdf'})]}"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# break it down\n",
        "query = \"How many young adults (or people) took part in this?\"\n",
        "llm_response = qa_chain(query)\n",
        "# process_llm_response(llm_response)\n",
        "llm_response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wg-e6fh6rNwz",
        "outputId": "4b8d1e0e-b039-4e21-c233-a6c308cc5e25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " They use the three items suggested by Kashdan and Steger67 (e.g., ‘I worried that I would say or do something wrong right now’) on a 7-point Likert scale (1 “not at all”–7 “very”).\n",
            "\n",
            "\n",
            "Sources:\n",
            "data/s41598-023-47912-0.pdf\n",
            "data/s41598-023-47912-0.pdf\n"
          ]
        }
      ],
      "source": [
        "query = \"How do they measure Momentary social anxiety?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuFf8D-rrN0I",
        "outputId": "19c63b88-33e2-4400-eede-f2678231eccb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Data collection took place in June to October 2021. It happened to be after the peak of the fourth wave of the COVID-19 pandemic in Hong Kong. While face-to-face data collection was allowed by the university, territory-wide infection control measures such as social distancing and mask-wearing mandate were in place. Consented participants attended a 1-h assessment session during which they were screened with the Structured Clinical Interview for Diagnostic and Statistical Manual of Mental Disorders-IV (SCI-DSM-IV; So et al.59).\n",
            "\n",
            "\n",
            "Sources:\n",
            "data/s41598-023-47912-0.pdf\n",
            "data/s41598-023-47912-0.pdf\n"
          ]
        }
      ],
      "source": [
        "query = \"What is their data collection method?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5KETxphrN3d",
        "outputId": "4f4a7dfb-0f5b-4b72-b678-6def5d056d20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ESM stands for Ecological Momentary Assessment.\n",
            "\n",
            "\n",
            "Sources:\n",
            "data/s41598-023-47912-0.pdf\n",
            "data/s41598-023-47912-0.pdf\n"
          ]
        }
      ],
      "source": [
        "query = \"What is ESM?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "692pHNkFrN5z",
        "outputId": "85124452-c208-4ec4-a35d-be28503ddc42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " This study did not find any results, as it was designed to assess the frequency of ESM assessment and the potential confounding impact of the pandemic on the expression of social anxiety and paranoia in daily life, not to determine any outcome.\n",
            "\n",
            "\n",
            "Sources:\n",
            "data/s41598-023-47912-0.pdf\n",
            "data/s41598-023-47912-0.pdf\n"
          ]
        }
      ],
      "source": [
        "query = \"What is the result of this study?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " The current study has several limitations. First, there is a limited frequency of ESM assessment. Second, the data collection was conducted during the COVID-19 pandemic and it is not clear how it impacted the expression of social anxiety and paranoia. Third, the sample was mostly composed of undergraduate students and it is not sure whether the results would be replicated in more diverse samples. Finally, the dynamics between social anxiety and paranoia may involve other unmeasured mechanisms.\n",
            "\n",
            "\n",
            "Sources:\n",
            "data/s41598-023-47912-0.pdf\n",
            "data/s41598-023-47912-0.pdf\n"
          ]
        }
      ],
      "source": [
        "query = \"What is the limitations of the current study?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " The hypothesis of the study is that the time series is either stationary (without time-dependent structure) or non-stationary (with time-dependent structure).\n",
            "\n",
            "\n",
            "Sources:\n",
            "data/Time Series Analysis.pdf\n",
            "data/Time Series Analysis.pdf\n"
          ]
        }
      ],
      "source": [
        "query = \"What is the hypothesis of the study?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 134 participants\n",
            "\n",
            "\n",
            "Sources:\n",
            "data/s41598-023-47912-0.pdf\n",
            "data/s41598-023-47912-0.pdf\n"
          ]
        }
      ],
      "source": [
        "query = \"What is the final sample size of the study?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " The study took place at The Chinese University of Hong Kong.\n",
            "\n",
            "\n",
            "Sources:\n",
            "data/s41598-023-47912-0.pdf\n",
            "data/s41598-023-47912-0.pdf\n"
          ]
        }
      ],
      "source": [
        "query = \"Where did the study take place?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPIhZWAR5n3X",
        "outputId": "68914c62-f8ed-4e22-d889-7991df441d53"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('similarity', <langchain.vectorstores.chroma.Chroma at 0x12ad845e0>)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "qa_chain.retriever.search_type , qa_chain.retriever.vectorstore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_lp0_796P_-",
        "outputId": "64c01726-6e78-4c12-e409-2fdc839f6611"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "\n",
            "{context}\n",
            "\n",
            "Question: {question}\n",
            "Helpful Answer:\n"
          ]
        }
      ],
      "source": [
        "print(qa_chain.combine_documents_chain.llm_chain.prompt.template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSxVCnNi5h1-"
      },
      "source": [
        "## Deleteing the DB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7xmepGJ2GAE",
        "outputId": "92b53c84-ef81-4000-db5a-2c2ec09db311"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: db/ (stored 0%)\n",
            "  adding: db/e8de396e-85e7-4500-ae31-36acd9dd3420/ (stored 0%)\n",
            "  adding: db/e8de396e-85e7-4500-ae31-36acd9dd3420/data_level0.bin (deflated 100%)\n",
            "  adding: db/e8de396e-85e7-4500-ae31-36acd9dd3420/length.bin (deflated 44%)\n",
            "  adding: db/e8de396e-85e7-4500-ae31-36acd9dd3420/link_lists.bin (stored 0%)\n",
            "  adding: db/e8de396e-85e7-4500-ae31-36acd9dd3420/header.bin (deflated 61%)\n",
            "  adding: db/chroma.sqlite3 (deflated 61%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r db.zip ./db"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Jl84qGQt5Wu5"
      },
      "outputs": [],
      "source": [
        "# To cleanup, you can delete the collection\n",
        "vectordb.delete_collection()\n",
        "vectordb.persist()\n",
        "\n",
        "# delete the directory\n",
        "!rm -rf db/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2r0ZIBPJp-K"
      },
      "source": [
        "## Starting again loading the db\n",
        "\n",
        "restart the runtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pc7CM_mTQAt",
        "outputId": "f8e311fb-7d68-43af-ffd6-f66a9259766a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  db.zip\n",
            "replace db/e8de396e-85e7-4500-ae31-36acd9dd3420/data_level0.bin? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
          ]
        }
      ],
      "source": [
        "!unzip db.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "us3F8ZKeRiz2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "OPEN_API_KEY = os.getenv(\"OPENAI_API_KEY\", None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qK1nY4PkKYGo"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import RetrievalQA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "396RyNbS4EXx",
        "outputId": "502d5c81-0823-4c00-89ca-7b4dd08bee26"
      },
      "outputs": [],
      "source": [
        "persist_directory = 'db'\n",
        "embedding = OpenAIEmbeddings()\n",
        "\n",
        "vectordb2 = Chroma(persist_directory=persist_directory,\n",
        "                  embedding_function=embedding,\n",
        "                   )\n",
        "\n",
        "retriever = vectordb2.as_retriever(search_kwargs={\"k\": 2})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "F3vkSxxYKCZ9"
      },
      "outputs": [],
      "source": [
        "# Set up the turbo LLM\n",
        "turbo_llm = ChatOpenAI(\n",
        "    temperature=0,\n",
        "    model_name='gpt-3.5-turbo'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PsR60NH5KCfj"
      },
      "outputs": [],
      "source": [
        "# create the chain to answer questions\n",
        "qa_chain = RetrievalQA.from_chain_type(llm=turbo_llm,\n",
        "                                  chain_type=\"stuff\",\n",
        "                                  retriever=retriever,\n",
        "                                  return_source_documents=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RWulTG0eKCfk"
      },
      "outputs": [],
      "source": [
        "## Cite sources\n",
        "def process_llm_response(llm_response):\n",
        "    print(llm_response['result'])\n",
        "    print('\\n\\nSources:')\n",
        "    for source in llm_response[\"source_documents\"]:\n",
        "        print(source.metadata['source'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDp-g2FtKCfk",
        "outputId": "766f131a-daaf-462f-842a-f7bd10a081fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I don't have any information about how much money Pando raised.\n",
            "\n",
            "\n",
            "Sources:\n",
            "data/Time Series Analysis.pdf\n",
            "data/Time Series Analysis.pdf\n"
          ]
        }
      ],
      "source": [
        "# full example\n",
        "query = \"How many young adults (or people) took part in this?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fPl26c-TbWw"
      },
      "source": [
        "### Chat prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwyuhrpu5XqM",
        "outputId": "0f2c8060-4002-49ba-8869-6a9990c2c6d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Use the following pieces of context to answer the user's question. \n",
            "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "----------------\n",
            "{context}\n"
          ]
        }
      ],
      "source": [
        "print(qa_chain.combine_documents_chain.llm_chain.prompt.messages[0].prompt.template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcWXvSCHRvHO",
        "outputId": "d7a3acee-9ef1-4c08-b2a0-187f2cd90c8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{question}\n"
          ]
        }
      ],
      "source": [
        "print(qa_chain.combine_documents_chain.llm_chain.prompt.messages[1].prompt.template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "978QWCeJSRdu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
